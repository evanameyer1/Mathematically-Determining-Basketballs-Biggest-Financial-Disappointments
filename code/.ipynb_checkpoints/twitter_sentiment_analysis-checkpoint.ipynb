{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "062eb4f8-2106-435d-a1b8-1735d63a463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textblob\n",
    "#!pip install tweepy\n",
    "#!pip install pycountry\n",
    "#!pip install wordcloud\n",
    "#!pip install langdetect\n",
    "#!pip install better_profanity\n",
    "#!pip install nbimporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41bdeccf-41e4-468a-8d20-82ec463046c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "from better_profanity import profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebee0bf0-3b6c-42d3-a6bf-35e2f6d77939",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'XXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "consumer_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "access_token = 'XXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "access_token_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b7d3260-1bba-4feb-b0c9-6f3336be4e69",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'API' object has no attribute 'search_all_tweets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24824\\3392944489.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0msince_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdate_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0muntil_date\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdate_range\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyze_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msince_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muntil_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24824\\3392944489.py\u001b[0m in \u001b[0;36manalyze_tweets\u001b[1;34m(query, since_date, until_date)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_all_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'extended'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msince_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msince_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muntil_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muntil_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTweepyException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Error:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'API' object has no attribute 'search_all_tweets'"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#Twitter API keys\n",
    "consumer_key = '3MX6HKSa9Z33xXWF73hK4ureO'\n",
    "consumer_secret = 'cP1vG4DSSPqcBppOsyZiXd5m34wyNFrpC2M4lqjf3sshQe4znl'\n",
    "access_token = '39207671-BW75JLnEvwqo3ft00NUEUXJNLJanK5oMgPoyfJWLj'\n",
    "access_token_secret = 'NFsNkOSPcErlxXBjHXLMTvjP16NaKHSCiEPPYoyJPqa4W'\n",
    "\n",
    "#Authenticate with the Twitter API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "#Define a function to search for tweets and perform sentiment analysis\n",
    "def analyze_tweets(query, since_date, until_date):\n",
    "    # Create an empty list to store the cleaned tweets\n",
    "    cleaned_tweets = []\n",
    "    # Search for tweets with the given query string and date range\n",
    "    api = tweepy.API(auth)\n",
    "    tweets = []\n",
    "    try:\n",
    "        tweets = api.search_tweets(q=query, count=100, tweet_mode='extended', since_id=since_date, until_id=until_date)\n",
    "    except tweepy.TweepyException as e:\n",
    "        print('Error:', e)\n",
    "        return None\n",
    "\n",
    "    # Wait for 1 second to avoid hitting the rate limit\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Clean the tweets and perform sentiment analysis on each one\n",
    "    positive_tweets = 0\n",
    "    negative_tweets = 0\n",
    "    for tweet in tweets:\n",
    "        # Extract the full text of the tweet\n",
    "        if tweet.full_text.startswith('RT'):\n",
    "            cleaned_tweet = tweet.retweeted_status.full_text\n",
    "        else:\n",
    "            cleaned_tweet = tweet.full_text\n",
    "\n",
    "        # Remove URLs, mentions, and special characters from the tweet text\n",
    "        cleaned_tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", cleaned_tweet).split())\n",
    "\n",
    "        # Perform sentiment analysis on the cleaned tweet using TextBlob\n",
    "        analysis = TextBlob(cleaned_tweet)\n",
    "\n",
    "        # Count the number of positive and negative tweets\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            positive_tweets += 1\n",
    "        elif analysis.sentiment.polarity < 0:\n",
    "            negative_tweets += 1\n",
    "\n",
    "        # Add the cleaned tweet to the list of cleaned tweets\n",
    "        cleaned_tweets.append(cleaned_tweet)\n",
    "\n",
    "    # Calculate the percentage of positive and negative tweets\n",
    "    total_tweets = len(cleaned_tweets)\n",
    "    if total_tweets > 0:\n",
    "        percent_positive = round((positive_tweets / total_tweets) * 100, 2)\n",
    "        percent_negative = round((negative_tweets / total_tweets) * 100, 2)\n",
    "    else:\n",
    "        percent_positive = 0\n",
    "        percent_negative = 0\n",
    "\n",
    "    # Create a data frame with the results and return it\n",
    "    data = {\n",
    "    'name': query,\n",
    "    'number of tweets': total_tweets,\n",
    "    '% positive': percent_positive,\n",
    "    '% negative': percent_negative,\n",
    "    'year': since_date.year}\n",
    "    return pd.DataFrame(data, index=[0])\n",
    "\n",
    "#Define a list of queries to search for\n",
    "queries = ['Michael Jordan']\n",
    "\n",
    "#Define a list of date ranges to search for\n",
    "date_ranges = [\n",
    "pd.date_range(start='01/01/2010', end='12/31/2010', freq='M'),\n",
    "pd.date_range(start='01/01/2011', end='12/31/2011', freq='M'),\n",
    "pd.date_range(start='01/01/2012', end='12/31/2012', freq='M')\n",
    "]\n",
    "\n",
    "#Search for tweets and perform sentiment analysis for each query and date range\n",
    "results = []\n",
    "for query in queries:\n",
    "    for date_range in date_ranges:\n",
    "        for i in range(len(date_range) - 1):\n",
    "            since_date = date_range[i]\n",
    "            until_date = date_range[i + 1]\n",
    "            result = analyze_tweets(query, since_date, until_date)\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "\n",
    "#Concatenate the results into separate data frames for each year\n",
    "data_frames = {}\n",
    "for result in results:\n",
    "    year = result['year'][0]\n",
    "    if year not in data_frames:\n",
    "        data_frames[year] = result\n",
    "    else:\n",
    "        data_frames[year] = pd.concat([data_frames[year], result], ignore_index=True)\n",
    "\n",
    "#Print the data frames for each year\n",
    "for year in data_frames:\n",
    "    print(f'Data Frame for {year}:')\n",
    "    print(data_frames[year])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
